[
  {
    "loss": 27.1828,
    "grad_norm": NaN,
    "learning_rate": 0.0,
    "epoch": 0.000676132521974307,
    "step": 1
  },
  {
    "loss": 25.4413,
    "grad_norm": 14.810718536376953,
    "learning_rate": 4.75e-06,
    "epoch": 0.0676132521974307,
    "step": 100
  },
  {
    "loss": 23.5565,
    "grad_norm": 12.307106971740723,
    "learning_rate": 9.75e-06,
    "epoch": 0.1352265043948614,
    "step": 200
  },
  {
    "loss": 22.5227,
    "grad_norm": 17.25704002380371,
    "learning_rate": 9.999276861899045e-06,
    "epoch": 0.2028397565922921,
    "step": 300
  },
  {
    "loss": 21.8979,
    "grad_norm": 17.178241729736328,
    "learning_rate": 9.996953440833089e-06,
    "epoch": 0.2704530087897228,
    "step": 400
  },
  {
    "loss": 21.9806,
    "grad_norm": 14.515521049499512,
    "learning_rate": 9.993028478266131e-06,
    "epoch": 0.3380662609871535,
    "step": 500
  },
  {
    "loss": 21.8235,
    "grad_norm": 10.938403129577637,
    "learning_rate": 9.987503232162754e-06,
    "epoch": 0.4056795131845842,
    "step": 600
  },
  {
    "loss": 21.4358,
    "grad_norm": 10.71835994720459,
    "learning_rate": 9.980379473384152e-06,
    "epoch": 0.47329276538201487,
    "step": 700
  },
  {
    "loss": 21.5501,
    "grad_norm": 14.459563255310059,
    "learning_rate": 9.971659485120564e-06,
    "epoch": 0.5409060175794456,
    "step": 800
  },
  {
    "loss": 21.5673,
    "grad_norm": 14.280468940734863,
    "learning_rate": 9.961346062159504e-06,
    "epoch": 0.6085192697768763,
    "step": 900
  },
  {
    "loss": 21.0664,
    "grad_norm": 24.650325775146484,
    "learning_rate": 9.949442509990028e-06,
    "epoch": 0.676132521974307,
    "step": 1000
  },
  {
    "loss": 21.2698,
    "grad_norm": 15.70755672454834,
    "learning_rate": 9.935952643743298e-06,
    "epoch": 0.7437457741717377,
    "step": 1100
  },
  {
    "loss": 20.907,
    "grad_norm": 12.301589965820312,
    "learning_rate": 9.920880786969833e-06,
    "epoch": 0.8113590263691683,
    "step": 1200
  },
  {
    "loss": 21.1256,
    "grad_norm": 22.500686645507812,
    "learning_rate": 9.904231770253792e-06,
    "epoch": 0.8789722785665991,
    "step": 1300
  },
  {
    "loss": 21.1167,
    "grad_norm": 13.696405410766602,
    "learning_rate": 9.886010929664744e-06,
    "epoch": 0.9465855307640297,
    "step": 1400
  },
  {
    "eval_map": 0.36320653557777405,
    "eval_loss": 6.9805443000793455,
    "eval_runtime": 148.8299,
    "eval_samples_per_second": 6.719,
    "eval_steps_per_second": 0.84,
    "epoch": 1.0,
    "step": 1479
  },
  {
    "loss": 20.8758,
    "grad_norm": 14.817232131958008,
    "learning_rate": 9.866429704506581e-06,
    "epoch": 1.0141987829614605,
    "step": 1500
  },
  {
    "loss": 20.8218,
    "grad_norm": 12.41673469543457,
    "learning_rate": 9.84509880099737e-06,
    "epoch": 1.0818120351588911,
    "step": 1600
  },
  {
    "loss": 20.8977,
    "grad_norm": 16.99319076538086,
    "learning_rate": 9.822215025943904e-06,
    "epoch": 1.1494252873563218,
    "step": 1700
  },
  {
    "loss": 20.8262,
    "grad_norm": 16.36773681640625,
    "learning_rate": 9.797785713678166e-06,
    "epoch": 1.2170385395537526,
    "step": 1800
  },
  {
    "loss": 20.8587,
    "grad_norm": 18.936304092407227,
    "learning_rate": 9.77181869388236e-06,
    "epoch": 1.2846517917511833,
    "step": 1900
  },
  {
    "loss": 20.7312,
    "grad_norm": 15.562414169311523,
    "learning_rate": 9.74432228907947e-06,
    "epoch": 1.352265043948614,
    "step": 2000
  },
  {
    "loss": 20.6454,
    "grad_norm": 14.411377906799316,
    "learning_rate": 9.71530531196586e-06,
    "epoch": 1.4198782961460445,
    "step": 2100
  },
  {
    "loss": 20.4609,
    "grad_norm": 13.845831871032715,
    "learning_rate": 9.684777062586774e-06,
    "epoch": 1.4874915483434754,
    "step": 2200
  },
  {
    "loss": 20.7311,
    "grad_norm": 21.92474937438965,
    "learning_rate": 9.65274732535564e-06,
    "epoch": 1.555104800540906,
    "step": 2300
  },
  {
    "loss": 20.7833,
    "grad_norm": 15.55021858215332,
    "learning_rate": 9.619226365918122e-06,
    "epoch": 1.6227180527383367,
    "step": 2400
  },
  {
    "loss": 20.5599,
    "grad_norm": 19.850738525390625,
    "learning_rate": 9.584224927861955e-06,
    "epoch": 1.6903313049357673,
    "step": 2500
  },
  {
    "loss": 20.6388,
    "grad_norm": 12.156205177307129,
    "learning_rate": 9.547754229273583e-06,
    "epoch": 1.757944557133198,
    "step": 2600
  },
  {
    "loss": 20.6334,
    "grad_norm": 12.356590270996094,
    "learning_rate": 9.509825959142713e-06,
    "epoch": 1.8255578093306288,
    "step": 2700
  },
  {
    "loss": 20.385,
    "grad_norm": 19.25477409362793,
    "learning_rate": 9.470452273615966e-06,
    "epoch": 1.8931710615280595,
    "step": 2800
  },
  {
    "loss": 20.6268,
    "grad_norm": 16.432907104492188,
    "learning_rate": 9.42964579210078e-06,
    "epoch": 1.9607843137254903,
    "step": 2900
  },
  {
    "eval_map": 0.3622153401374817,
    "eval_loss": 7.030994239807129,
    "eval_runtime": 137.2173,
    "eval_samples_per_second": 7.288,
    "eval_steps_per_second": 0.911,
    "epoch": 2.0,
    "step": 2958
  },
  {
    "loss": 20.7334,
    "grad_norm": 13.598054885864258,
    "learning_rate": 9.38741959322085e-06,
    "epoch": 2.028397565922921,
    "step": 3000
  },
  {
    "loss": 20.2287,
    "grad_norm": 15.338262557983398,
    "learning_rate": 9.34378721062437e-06,
    "epoch": 2.0960108181203516,
    "step": 3100
  },
  {
    "loss": 20.482,
    "grad_norm": 25.028226852416992,
    "learning_rate": 9.298762628646465e-06,
    "epoch": 2.1636240703177823,
    "step": 3200
  },
  {
    "loss": 20.6276,
    "grad_norm": 20.411142349243164,
    "learning_rate": 9.252360277827154e-06,
    "epoch": 2.231237322515213,
    "step": 3300
  },
  {
    "loss": 20.4541,
    "grad_norm": 13.224827766418457,
    "learning_rate": 9.204595030286317e-06,
    "epoch": 2.2988505747126435,
    "step": 3400
  },
  {
    "loss": 20.448,
    "grad_norm": 16.939191818237305,
    "learning_rate": 9.155482194957111e-06,
    "epoch": 2.366463826910074,
    "step": 3500
  },
  {
    "loss": 20.3196,
    "grad_norm": 16.94366455078125,
    "learning_rate": 9.10503751267942e-06,
    "epoch": 2.4340770791075053,
    "step": 3600
  },
  {
    "loss": 20.2297,
    "grad_norm": 22.03032684326172,
    "learning_rate": 9.05327715115485e-06,
    "epoch": 2.501690331304936,
    "step": 3700
  },
  {
    "loss": 20.3093,
    "grad_norm": 14.811117172241211,
    "learning_rate": 9.000217699764926e-06,
    "epoch": 2.5693035835023665,
    "step": 3800
  },
  {
    "loss": 20.2945,
    "grad_norm": 18.152353286743164,
    "learning_rate": 8.945876164254133e-06,
    "epoch": 2.636916835699797,
    "step": 3900
  },
  {
    "loss": 20.3735,
    "grad_norm": 16.063169479370117,
    "learning_rate": 8.890269961279517e-06,
    "epoch": 2.704530087897228,
    "step": 4000
  },
  {
    "loss": 20.0409,
    "grad_norm": 13.664258003234863,
    "learning_rate": 8.833416912828579e-06,
    "epoch": 2.7721433400946585,
    "step": 4100
  },
  {
    "loss": 20.3001,
    "grad_norm": 11.379796981811523,
    "learning_rate": 8.775335240507272e-06,
    "epoch": 2.839756592292089,
    "step": 4200
  },
  {
    "loss": 20.3186,
    "grad_norm": 18.200773239135742,
    "learning_rate": 8.716043559699904e-06,
    "epoch": 2.90736984448952,
    "step": 4300
  },
  {
    "loss": 20.0594,
    "grad_norm": 18.211750030517578,
    "learning_rate": 8.655560873602842e-06,
    "epoch": 2.974983096686951,
    "step": 4400
  },
  {
    "eval_map": 0.3488880693912506,
    "eval_loss": 7.137162872314454,
    "eval_runtime": 139.0221,
    "eval_samples_per_second": 7.193,
    "eval_steps_per_second": 0.899,
    "epoch": 3.0,
    "step": 4437
  },
  {
    "loss": 20.2322,
    "grad_norm": 36.693458557128906,
    "learning_rate": 8.593906567133919e-06,
    "epoch": 3.0425963488843815,
    "step": 4500
  },
  {
    "loss": 19.8914,
    "grad_norm": 56.89897155761719,
    "learning_rate": 8.531100400719505e-06,
    "epoch": 3.110209601081812,
    "step": 4600
  },
  {
    "loss": 19.846,
    "grad_norm": 31.525083541870117,
    "learning_rate": 8.467162503961209e-06,
    "epoch": 3.1778228532792427,
    "step": 4700
  },
  {
    "loss": 19.4223,
    "grad_norm": 45.970882415771484,
    "learning_rate": 8.402113369184276e-06,
    "epoch": 3.2454361054766734,
    "step": 4800
  },
  {
    "loss": 19.3282,
    "grad_norm": 46.2780647277832,
    "learning_rate": 8.335973844869726e-06,
    "epoch": 3.313049357674104,
    "step": 4900
  },
  {
    "loss": 19.2826,
    "grad_norm": 36.03635025024414,
    "learning_rate": 8.268765128972327e-06,
    "epoch": 3.3806626098715347,
    "step": 5000
  },
  {
    "loss": 19.3786,
    "grad_norm": 58.389625549316406,
    "learning_rate": 8.200508762126596e-06,
    "epoch": 3.4482758620689653,
    "step": 5100
  },
  {
    "loss": 19.0992,
    "grad_norm": 36.416717529296875,
    "learning_rate": 8.131226620742924e-06,
    "epoch": 3.515889114266396,
    "step": 5200
  },
  {
    "loss": 19.3981,
    "grad_norm": 38.3615608215332,
    "learning_rate": 8.060940909996134e-06,
    "epoch": 3.583502366463827,
    "step": 5300
  },
  {
    "loss": 19.2428,
    "grad_norm": 27.3684139251709,
    "learning_rate": 7.98967415670862e-06,
    "epoch": 3.6511156186612577,
    "step": 5400
  },
  {
    "loss": 19.0593,
    "grad_norm": 36.371315002441406,
    "learning_rate": 7.917449202130434e-06,
    "epoch": 3.7187288708586883,
    "step": 5500
  },
  {
    "loss": 19.0654,
    "grad_norm": 64.31497955322266,
    "learning_rate": 7.844289194618575e-06,
    "epoch": 3.786342123056119,
    "step": 5600
  },
  {
    "loss": 19.3648,
    "grad_norm": 29.6320858001709,
    "learning_rate": 7.770962733073545e-06,
    "epoch": 3.8539553752535496,
    "step": 5700
  },
  {
    "loss": 19.1446,
    "grad_norm": 37.86708450317383,
    "learning_rate": 7.696012016193356e-06,
    "epoch": 3.9215686274509802,
    "step": 5800
  },
  {
    "loss": 19.047,
    "grad_norm": 35.288368225097656,
    "learning_rate": 7.620197217791845e-06,
    "epoch": 3.9891818796484113,
    "step": 5900
  },
  {
    "eval_map": 0.38681700825691223,
    "eval_loss": 6.769470867156983,
    "eval_runtime": 109.6548,
    "eval_samples_per_second": 9.12,
    "eval_steps_per_second": 1.14,
    "epoch": 4.0,
    "step": 5916
  },
  {
    "loss": 18.9506,
    "grad_norm": 40.48917007446289,
    "learning_rate": 7.543542636783835e-06,
    "epoch": 4.056795131845842,
    "step": 6000
  },
  {
    "loss": 19.1066,
    "grad_norm": 47.078346252441406,
    "learning_rate": 7.466072841237484e-06,
    "epoch": 4.124408384043273,
    "step": 6100
  },
  {
    "loss": 19.0492,
    "grad_norm": 38.13929748535156,
    "learning_rate": 7.387812660500137e-06,
    "epoch": 4.192021636240703,
    "step": 6200
  },
  {
    "loss": 18.8518,
    "grad_norm": 39.30044174194336,
    "learning_rate": 7.308787177240426e-06,
    "epoch": 4.259634888438134,
    "step": 6300
  },
  {
    "loss": 18.9777,
    "grad_norm": 58.85293960571289,
    "learning_rate": 7.229021719409185e-06,
    "epoch": 4.3272481406355645,
    "step": 6400
  },
  {
    "loss": 19.1539,
    "grad_norm": 58.12301254272461,
    "learning_rate": 7.148541852121755e-06,
    "epoch": 4.394861392832995,
    "step": 6500
  },
  {
    "loss": 18.7926,
    "grad_norm": 33.09135818481445,
    "learning_rate": 7.067373369464271e-06,
    "epoch": 4.462474645030426,
    "step": 6600
  },
  {
    "loss": 18.6794,
    "grad_norm": 44.514957427978516,
    "learning_rate": 6.985542286226559e-06,
    "epoch": 4.530087897227856,
    "step": 6700
  },
  {
    "loss": 18.9203,
    "grad_norm": 41.989315032958984,
    "learning_rate": 6.903074829564314e-06,
    "epoch": 4.597701149425287,
    "step": 6800
  },
  {
    "loss": 18.6564,
    "grad_norm": 42.562355041503906,
    "learning_rate": 6.819997430593188e-06,
    "epoch": 4.665314401622718,
    "step": 6900
  },
  {
    "loss": 18.6023,
    "grad_norm": 38.28253936767578,
    "learning_rate": 6.7363367159175405e-06,
    "epoch": 4.732927653820148,
    "step": 7000
  },
  {
    "loss": 18.7968,
    "grad_norm": 30.21917724609375,
    "learning_rate": 6.6521194990965e-06,
    "epoch": 4.800540906017579,
    "step": 7100
  },
  {
    "loss": 18.8345,
    "grad_norm": 32.0079231262207,
    "learning_rate": 6.567372772050129e-06,
    "epoch": 4.8681541582150105,
    "step": 7200
  },
  {
    "loss": 18.6904,
    "grad_norm": 67.12236022949219,
    "learning_rate": 6.48212369640842e-06,
    "epoch": 4.935767410412441,
    "step": 7300
  },
  {
    "eval_map": 0.39196979999542236,
    "eval_loss": 6.805518459320068,
    "eval_runtime": 107.6195,
    "eval_samples_per_second": 9.292,
    "eval_steps_per_second": 1.161,
    "epoch": 5.0,
    "step": 7395
  },
  {
    "loss": 18.7889,
    "grad_norm": 40.33330154418945,
    "learning_rate": 6.396399594805888e-06,
    "epoch": 5.003380662609872,
    "step": 7400
  },
  {
    "loss": 18.4582,
    "grad_norm": 35.64418411254883,
    "learning_rate": 6.310227942124574e-06,
    "epoch": 5.070993914807302,
    "step": 7500
  },
  {
    "loss": 18.83,
    "grad_norm": 67.53398132324219,
    "learning_rate": 6.223636356688248e-06,
    "epoch": 5.138607167004733,
    "step": 7600
  },
  {
    "loss": 18.8731,
    "grad_norm": 27.141746520996094,
    "learning_rate": 6.137524278913998e-06,
    "epoch": 5.206220419202164,
    "step": 7700
  },
  {
    "loss": 18.7443,
    "grad_norm": 31.6878662109375,
    "learning_rate": 6.0501797170262564e-06,
    "epoch": 5.273833671399594,
    "step": 7800
  },
  {
    "loss": 18.6078,
    "grad_norm": 34.82844924926758,
    "learning_rate": 5.962498568772397e-06,
    "epoch": 5.341446923597025,
    "step": 7900
  },
  {
    "loss": 18.6955,
    "grad_norm": 41.90316390991211,
    "learning_rate": 5.874508936274927e-06,
    "epoch": 5.409060175794456,
    "step": 8000
  },
  {
    "loss": 18.5985,
    "grad_norm": 36.44583511352539,
    "learning_rate": 5.786239020526669e-06,
    "epoch": 5.476673427991886,
    "step": 8100
  },
  {
    "loss": 18.5801,
    "grad_norm": 40.44459915161133,
    "learning_rate": 5.6977171123522276e-06,
    "epoch": 5.544286680189317,
    "step": 8200
  },
  {
    "loss": 18.5651,
    "grad_norm": 47.040523529052734,
    "learning_rate": 5.608971583340684e-06,
    "epoch": 5.611899932386748,
    "step": 8300
  },
  {
    "loss": 18.4543,
    "grad_norm": 35.56636428833008,
    "learning_rate": 5.520030876752404e-06,
    "epoch": 5.679513184584178,
    "step": 8400
  },
  {
    "loss": 18.5864,
    "grad_norm": 34.29324722290039,
    "learning_rate": 5.430923498402864e-06,
    "epoch": 5.747126436781609,
    "step": 8500
  },
  {
    "loss": 18.6526,
    "grad_norm": 32.30059051513672,
    "learning_rate": 5.341678007526437e-06,
    "epoch": 5.81473968897904,
    "step": 8600
  },
  {
    "loss": 18.4456,
    "grad_norm": 32.627559661865234,
    "learning_rate": 5.252323007623058e-06,
    "epoch": 5.882352941176471,
    "step": 8700
  },
  {
    "loss": 18.5321,
    "grad_norm": 40.135982513427734,
    "learning_rate": 5.162887137290696e-06,
    "epoch": 5.949966193373902,
    "step": 8800
  },
  {
    "eval_map": 0.39021623134613037,
    "eval_loss": 6.797806846618652,
    "eval_runtime": 125.2199,
    "eval_samples_per_second": 7.986,
    "eval_steps_per_second": 0.998,
    "epoch": 6.0,
    "step": 8874
  },
  {
    "loss": 18.2885,
    "grad_norm": 51.36803436279297,
    "learning_rate": 5.073399061046584e-06,
    "epoch": 6.017579445571332,
    "step": 8900
  },
  {
    "loss": 18.3576,
    "grad_norm": 28.71054458618164,
    "learning_rate": 4.983887460140138e-06,
    "epoch": 6.085192697768763,
    "step": 9000
  },
  {
    "loss": 18.4818,
    "grad_norm": 37.469970703125,
    "learning_rate": 4.894381023360508e-06,
    "epoch": 6.152805949966194,
    "step": 9100
  },
  {
    "loss": 18.4602,
    "grad_norm": 31.12598991394043,
    "learning_rate": 4.804908437841729e-06,
    "epoch": 6.220419202163624,
    "step": 9200
  },
  {
    "loss": 18.4417,
    "grad_norm": 39.158348083496094,
    "learning_rate": 4.715498379868381e-06,
    "epoch": 6.288032454361055,
    "step": 9300
  },
  {
    "loss": 18.2846,
    "grad_norm": 45.56658172607422,
    "learning_rate": 4.626179505684744e-06,
    "epoch": 6.3556457065584855,
    "step": 9400
  },
  {
    "loss": 18.4863,
    "grad_norm": 30.899372100830078,
    "learning_rate": 4.536980442310367e-06,
    "epoch": 6.423258958755916,
    "step": 9500
  },
  {
    "loss": 18.1667,
    "grad_norm": 30.331727981567383,
    "learning_rate": 4.447929778364999e-06,
    "epoch": 6.490872210953347,
    "step": 9600
  },
  {
    "loss": 18.2233,
    "grad_norm": 30.060697555541992,
    "learning_rate": 4.359943822705129e-06,
    "epoch": 6.558485463150777,
    "step": 9700
  },
  {
    "loss": 18.2924,
    "grad_norm": 49.9169807434082,
    "learning_rate": 4.271273329042108e-06,
    "epoch": 6.626098715348208,
    "step": 9800
  },
  {
    "loss": 18.5206,
    "grad_norm": 37.48418426513672,
    "learning_rate": 4.182836394890945e-06,
    "epoch": 6.693711967545639,
    "step": 9900
  },
  {
    "loss": 18.39,
    "grad_norm": 40.901458740234375,
    "learning_rate": 4.094661364606247e-06,
    "epoch": 6.761325219743069,
    "step": 10000
  },
  {
    "loss": 18.3735,
    "grad_norm": 36.70734786987305,
    "learning_rate": 4.006776498601488e-06,
    "epoch": 6.8289384719405,
    "step": 10100
  },
  {
    "loss": 18.3187,
    "grad_norm": 34.84296798706055,
    "learning_rate": 3.920083961650902e-06,
    "epoch": 6.896551724137931,
    "step": 10200
  },
  {
    "loss": 18.2624,
    "grad_norm": 42.124855041503906,
    "learning_rate": 3.8328602218865095e-06,
    "epoch": 6.964164976335361,
    "step": 10300
  },
  {
    "eval_map": 0.3855639398097992,
    "eval_loss": 6.816909973144531,
    "eval_runtime": 124.1853,
    "eval_samples_per_second": 8.052,
    "eval_steps_per_second": 1.007,
    "epoch": 7.0,
    "step": 10353
  },
  {
    "loss": 18.28,
    "grad_norm": 37.711151123046875,
    "learning_rate": 3.7460105546073334e-06,
    "epoch": 7.031778228532793,
    "step": 10400
  },
  {
    "loss": 18.1278,
    "grad_norm": 32.494747161865234,
    "learning_rate": 3.65956279544325e-06,
    "epoch": 7.099391480730223,
    "step": 10500
  },
  {
    "loss": 18.2619,
    "grad_norm": 35.97760772705078,
    "learning_rate": 3.5735446512111467e-06,
    "epoch": 7.167004732927654,
    "step": 10600
  },
  {
    "loss": 18.1998,
    "grad_norm": 30.87247657775879,
    "learning_rate": 3.4879836910347797e-06,
    "epoch": 7.234617985125085,
    "step": 10700
  },
  {
    "loss": 18.2206,
    "grad_norm": 44.27995300292969,
    "learning_rate": 3.402907337508778e-06,
    "epoch": 7.302231237322515,
    "step": 10800
  },
  {
    "loss": 18.2707,
    "grad_norm": 32.276180267333984,
    "learning_rate": 3.318342857909603e-06,
    "epoch": 7.369844489519946,
    "step": 10900
  },
  {
    "loss": 18.1782,
    "grad_norm": 39.646549224853516,
    "learning_rate": 3.2343173554562823e-06,
    "epoch": 7.437457741717377,
    "step": 11000
  },
  {
    "loss": 18.2778,
    "grad_norm": 45.816165924072266,
    "learning_rate": 3.150857760623739e-06,
    "epoch": 7.505070993914807,
    "step": 11100
  },
  {
    "loss": 18.3315,
    "grad_norm": 67.23110961914062,
    "learning_rate": 3.067990822511473e-06,
    "epoch": 7.572684246112238,
    "step": 11200
  },
  {
    "loss": 18.4217,
    "grad_norm": 28.757768630981445,
    "learning_rate": 2.985743100270375e-06,
    "epoch": 7.6402974983096685,
    "step": 11300
  },
  {
    "loss": 18.3109,
    "grad_norm": 41.7775764465332,
    "learning_rate": 2.904140954590434e-06,
    "epoch": 7.707910750507099,
    "step": 11400
  },
  {
    "loss": 17.8818,
    "grad_norm": 56.06480407714844,
    "learning_rate": 2.8232105392520335e-06,
    "epoch": 7.77552400270453,
    "step": 11500
  },
  {
    "loss": 18.1514,
    "grad_norm": 37.11833953857422,
    "learning_rate": 2.7429777927435752e-06,
    "epoch": 7.8431372549019605,
    "step": 11600
  },
  {
    "loss": 18.1052,
    "grad_norm": 50.28184509277344,
    "learning_rate": 2.6634684299480917e-06,
    "epoch": 7.910750507099391,
    "step": 11700
  },
  {
    "loss": 18.1766,
    "grad_norm": 32.13028335571289,
    "learning_rate": 2.584707933901549e-06,
    "epoch": 7.978363759296823,
    "step": 11800
  },
  {
    "eval_map": 0.38842499256134033,
    "eval_loss": 6.805208431243896,
    "eval_runtime": 124.5189,
    "eval_samples_per_second": 8.031,
    "eval_steps_per_second": 1.004,
    "epoch": 8.0,
    "step": 11832
  },
  {
    "loss": 18.2837,
    "grad_norm": 48.50045394897461,
    "learning_rate": 2.506721547625427e-06,
    "epoch": 8.045977011494253,
    "step": 11900
  },
  {
    "loss": 18.0894,
    "grad_norm": 46.4625129699707,
    "learning_rate": 2.4295342660362524e-06,
    "epoch": 8.113590263691684,
    "step": 12000
  },
  {
    "loss": 18.1168,
    "grad_norm": 42.25981903076172,
    "learning_rate": 2.3531708279346347e-06,
    "epoch": 8.181203515889115,
    "step": 12100
  },
  {
    "loss": 18.0739,
    "grad_norm": 42.24854278564453,
    "learning_rate": 2.277655708076384e-06,
    "epoch": 8.248816768086545,
    "step": 12200
  },
  {
    "loss": 17.9267,
    "grad_norm": 37.8830680847168,
    "learning_rate": 2.203013109328278e-06,
    "epoch": 8.316430020283976,
    "step": 12300
  },
  {
    "loss": 18.0843,
    "grad_norm": 46.257667541503906,
    "learning_rate": 2.1292669549109423e-06,
    "epoch": 8.384043272481406,
    "step": 12400
  },
  {
    "loss": 17.9997,
    "grad_norm": 89.29241180419922,
    "learning_rate": 2.0564408807313845e-06,
    "epoch": 8.451656524678837,
    "step": 12500
  },
  {
    "loss": 18.033,
    "grad_norm": 27.94379425048828,
    "learning_rate": 1.9845582278075953e-06,
    "epoch": 8.519269776876268,
    "step": 12600
  },
  {
    "loss": 18.2475,
    "grad_norm": 61.81186294555664,
    "learning_rate": 1.913642034787663e-06,
    "epoch": 8.586883029073698,
    "step": 12700
  },
  {
    "loss": 18.3024,
    "grad_norm": 25.829360961914062,
    "learning_rate": 1.8437150305658186e-06,
    "epoch": 8.654496281271129,
    "step": 12800
  },
  {
    "loss": 18.0319,
    "grad_norm": 31.258502960205078,
    "learning_rate": 1.7747996269977314e-06,
    "epoch": 8.72210953346856,
    "step": 12900
  },
  {
    "loss": 18.0481,
    "grad_norm": 27.015687942504883,
    "learning_rate": 1.7069179117174295e-06,
    "epoch": 8.78972278566599,
    "step": 13000
  },
  {
    "loss": 18.0672,
    "grad_norm": 35.02412414550781,
    "learning_rate": 1.6400916410581425e-06,
    "epoch": 8.857336037863421,
    "step": 13100
  },
  {
    "loss": 18.2341,
    "grad_norm": 35.957759857177734,
    "learning_rate": 1.5743422330793122e-06,
    "epoch": 8.924949290060852,
    "step": 13200
  },
  {
    "loss": 18.0918,
    "grad_norm": 43.16839599609375,
    "learning_rate": 1.509690760702025e-06,
    "epoch": 8.992562542258282,
    "step": 13300
  },
  {
    "eval_map": 0.39323070645332336,
    "eval_loss": 6.810240329742432,
    "eval_runtime": 126.2327,
    "eval_samples_per_second": 7.922,
    "eval_steps_per_second": 0.99,
    "epoch": 9.0,
    "step": 13311
  },
  {
    "loss": 18.005,
    "grad_norm": 43.9517936706543,
    "learning_rate": 1.4461579449550721e-06,
    "epoch": 9.060175794455713,
    "step": 13400
  },
  {
    "loss": 17.9066,
    "grad_norm": 39.06563186645508,
    "learning_rate": 1.383764148333785e-06,
    "epoch": 9.127789046653144,
    "step": 13500
  },
  {
    "loss": 18.0745,
    "grad_norm": 35.980037689208984,
    "learning_rate": 1.3225293682737717e-06,
    "epoch": 9.195402298850574,
    "step": 13600
  },
  {
    "loss": 18.0261,
    "grad_norm": 72.41441345214844,
    "learning_rate": 1.2624732307416844e-06,
    "epoch": 9.263015551048005,
    "step": 13700
  },
  {
    "loss": 18.045,
    "grad_norm": 41.95927810668945,
    "learning_rate": 1.2036149839450095e-06,
    "epoch": 9.330628803245435,
    "step": 13800
  },
  {
    "loss": 18.1603,
    "grad_norm": 33.832489013671875,
    "learning_rate": 1.1459734921629612e-06,
    "epoch": 9.398242055442866,
    "step": 13900
  },
  {
    "loss": 18.0971,
    "grad_norm": 47.50758743286133,
    "learning_rate": 1.0895672297004079e-06,
    "epoch": 9.465855307640297,
    "step": 14000
  },
  {
    "loss": 17.9907,
    "grad_norm": 50.38615036010742,
    "learning_rate": 1.034414274966785e-06,
    "epoch": 9.53346855983773,
    "step": 14100
  },
  {
    "loss": 17.9537,
    "grad_norm": 40.9592170715332,
    "learning_rate": 9.81064775967282e-07,
    "epoch": 9.601081812035158,
    "step": 14200
  },
  {
    "loss": 18.117,
    "grad_norm": 50.18244552612305,
    "learning_rate": 9.284580928256082e-07,
    "epoch": 9.66869506423259,
    "step": 14300
  },
  {
    "loss": 17.9174,
    "grad_norm": 46.835147857666016,
    "learning_rate": 8.77662857052951e-07,
    "epoch": 9.736308316430021,
    "step": 14400
  },
  {
    "loss": 18.1669,
    "grad_norm": 29.183969497680664,
    "learning_rate": 8.276692100077793e-07,
    "epoch": 9.803921568627452,
    "step": 14500
  },
  {
    "loss": 17.9555,
    "grad_norm": 40.26062774658203,
    "learning_rate": 7.790128099462352e-07,
    "epoch": 9.871534820824882,
    "step": 14600
  },
  {
    "loss": 17.7884,
    "grad_norm": 48.832218170166016,
    "learning_rate": 7.317092514190582e-07,
    "epoch": 9.939148073022313,
    "step": 14700
  },
  {
    "eval_map": 0.38942429423332214,
    "eval_loss": 6.842105735778809,
    "eval_runtime": 126.0664,
    "eval_samples_per_second": 7.932,
    "eval_steps_per_second": 0.992,
    "epoch": 10.0,
    "step": 14790
  },
  {
    "loss": 17.9568,
    "grad_norm": 48.69610595703125,
    "learning_rate": 6.85773695386428e-07,
    "epoch": 10.006761325219744,
    "step": 14800
  },
  {
    "loss": 17.9457,
    "grad_norm": 33.98501205444336,
    "learning_rate": 6.412208643588164e-07,
    "epoch": 10.074374577417174,
    "step": 14900
  },
  {
    "loss": 17.9316,
    "grad_norm": 31.56778335571289,
    "learning_rate": 5.980650376783692e-07,
    "epoch": 10.141987829614605,
    "step": 15000
  },
  {
    "loss": 17.8788,
    "grad_norm": 59.09732437133789,
    "learning_rate": 5.563200469423318e-07,
    "epoch": 10.209601081812036,
    "step": 15100
  },
  {
    "loss": 18.1428,
    "grad_norm": 35.77683639526367,
    "learning_rate": 5.159992715699652e-07,
    "epoch": 10.277214334009466,
    "step": 15200
  },
  {
    "loss": 17.8637,
    "grad_norm": 28.8430118560791,
    "learning_rate": 4.771156345144018e-07,
    "epoch": 10.344827586206897,
    "step": 15300
  },
  {
    "loss": 18.0665,
    "grad_norm": 26.778125762939453,
    "learning_rate": 4.396815981207869e-07,
    "epoch": 10.412440838404327,
    "step": 15400
  },
  {
    "loss": 18.0039,
    "grad_norm": 32.01616668701172,
    "learning_rate": 4.037091601320531e-07,
    "epoch": 10.480054090601758,
    "step": 15500
  },
  {
    "loss": 17.9695,
    "grad_norm": 37.47245407104492,
    "learning_rate": 3.692098498436025e-07,
    "epoch": 10.547667342799189,
    "step": 15600
  },
  {
    "loss": 17.9131,
    "grad_norm": 45.67517852783203,
    "learning_rate": 3.361947244081271e-07,
    "epoch": 10.61528059499662,
    "step": 15700
  },
  {
    "loss": 17.8762,
    "grad_norm": 35.40871810913086,
    "learning_rate": 3.046743652917472e-07,
    "epoch": 10.68289384719405,
    "step": 15800
  },
  {
    "loss": 17.8533,
    "grad_norm": 39.84785461425781,
    "learning_rate": 2.7465887488261843e-07,
    "epoch": 10.75050709939148,
    "step": 15900
  },
  {
    "loss": 18.0526,
    "grad_norm": 32.228309631347656,
    "learning_rate": 2.461578732530767e-07,
    "epoch": 10.818120351588911,
    "step": 16000
  },
  {
    "loss": 18.1304,
    "grad_norm": 41.90095901489258,
    "learning_rate": 2.1918049507637318e-07,
    "epoch": 10.885733603786342,
    "step": 16100
  },
  {
    "loss": 18.072,
    "grad_norm": 40.428367614746094,
    "learning_rate": 1.9373538669897607e-07,
    "epoch": 10.953346855983773,
    "step": 16200
  },
  {
    "eval_map": 0.39194801449775696,
    "eval_loss": 6.802779373168946,
    "eval_runtime": 124.9856,
    "eval_samples_per_second": 8.001,
    "eval_steps_per_second": 1.0,
    "epoch": 11.0,
    "step": 16269
  },
  {
    "loss": 18.0954,
    "grad_norm": 54.78723907470703,
    "learning_rate": 1.6983070336938857e-07,
    "epoch": 11.020960108181203,
    "step": 16300
  },
  {
    "loss": 18.0469,
    "grad_norm": 29.862041473388672,
    "learning_rate": 1.4747410662435902e-07,
    "epoch": 11.088573360378634,
    "step": 16400
  },
  {
    "loss": 17.9838,
    "grad_norm": 35.21897506713867,
    "learning_rate": 1.2667276183333356e-07,
    "epoch": 11.156186612576064,
    "step": 16500
  },
  {
    "loss": 17.8779,
    "grad_norm": 85.63385009765625,
    "learning_rate": 1.0743333590192861e-07,
    "epoch": 11.223799864773495,
    "step": 16600
  },
  {
    "loss": 17.9337,
    "grad_norm": 47.84661865234375,
    "learning_rate": 8.976199513516359e-08,
    "epoch": 11.291413116970926,
    "step": 16700
  },
  {
    "loss": 17.9845,
    "grad_norm": 29.136554718017578,
    "learning_rate": 7.366440326113888e-08,
    "epoch": 11.359026369168356,
    "step": 16800
  },
  {
    "loss": 18.0337,
    "grad_norm": 38.635093688964844,
    "learning_rate": 5.9145719615788524e-08,
    "epoch": 11.426639621365787,
    "step": 16900
  },
  {
    "loss": 17.9278,
    "grad_norm": 36.159934997558594,
    "learning_rate": 4.621059748929735e-08,
    "epoch": 11.494252873563218,
    "step": 17000
  },
  {
    "loss": 18.0256,
    "grad_norm": 32.410526275634766,
    "learning_rate": 3.4863182634702895e-08,
    "epoch": 11.561866125760648,
    "step": 17100
  },
  {
    "loss": 17.7822,
    "grad_norm": 42.40400695800781,
    "learning_rate": 2.5107111939167705e-08,
    "epoch": 11.629479377958079,
    "step": 17200
  },
  {
    "loss": 17.9073,
    "grad_norm": 42.10694122314453,
    "learning_rate": 1.6945512258342288e-08,
    "epoch": 11.69709263015551,
    "step": 17300
  },
  {
    "loss": 17.9088,
    "grad_norm": 39.5800895690918,
    "learning_rate": 1.038099941419901e-08,
    "epoch": 11.764705882352942,
    "step": 17400
  },
  {
    "loss": 18.2481,
    "grad_norm": 42.549259185791016,
    "learning_rate": 5.415677356650495e-09,
    "epoch": 11.832319134550373,
    "step": 17500
  },
  {
    "loss": 17.9505,
    "grad_norm": 44.833675384521484,
    "learning_rate": 2.0511374892256963e-09,
    "epoch": 11.899932386747803,
    "step": 17600
  },
  {
    "loss": 17.8983,
    "grad_norm": 40.89774703979492,
    "learning_rate": 2.98153461895101e-10,
    "epoch": 11.967545638945234,
    "step": 17700
  },
  {
    "eval_map": 0.3997434079647064,
    "eval_loss": 6.7942666015625,
    "eval_runtime": 125.831,
    "eval_samples_per_second": 7.947,
    "eval_steps_per_second": 0.993,
    "epoch": 12.0,
    "step": 17748
  },
  {
    "train_runtime": 36158.8643,
    "train_samples_per_second": 7.851,
    "train_steps_per_second": 0.491,
    "total_flos": 0.0,
    "train_loss": 19.029786470803103,
    "epoch": 12.0,
    "step": 17748
  }
]